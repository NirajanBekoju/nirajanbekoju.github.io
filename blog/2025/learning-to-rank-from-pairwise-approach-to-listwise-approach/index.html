<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <h3>Introduction</h3> <p>Learning to rank is concerned with a model or a function for ranking objects which is useful for various applications like document retrieval and collaborative filtering. The paper introduces two probability model: <strong>permutation probability and top one probability.</strong></p> <p>In document retrieval, there is a collection of documents. Given a query, the ranking function assigns a score to each document, and ranks the document in descending order of the scores. The ranking order represents the relative relevance of documents w.r.t. to the query.</p> <p>While training, a number of queries are provided; each query is associated with a perfect ranking list of documents; a ranking function is then created using the training data, such that the model can precisely predict the ranking lists in the training data.</p> <p>To calculate the listwise loss function, both the scores of documents assigned by a ranking function and the explicit or implicit judgments of the documents given by humans are transformed into the probability distribution. Then an metric between the probability distribution can be used as the loss function.</p> <p>The major contribution of the paper are:</p> <ul> <li>proposal of the listwise approach</li> <li>formulation of the listwise loss function on the basis of probability models</li> <li>development of the ListNet method</li> <li>empirical verification of the effectiveness of the approach</li> </ul> <h3>Pairwise approach</h3> <p>In pairwise approach, the learning task is formalized as the classification of object pairs into two categories (correctly ranked and incorrectly ranked).</p> <h3>Permutation Probability</h3> <figure><img alt="" src="https://cdn-images-1.medium.com/max/770/1*PotEAldsDw_CvzZCU-0wlQ.jpeg"></figure> <h3>Top One Probability</h3> <p>The top one probability of on object represents the probability of its being ranked on the top, given the scores of all the objects.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/633/1*b3PeX4dasQndwS1JFyF40A.png"></figure> <figure><img alt="" src="https://cdn-images-1.medium.com/max/633/1*5iEhkJ6eIEPF9YaYV7Yh_w.png"></figure> <h3>Learning Method: ListNet</h3> <p>The paper developed a new learning method for optimizing the listwise loss function based on top one probability, with neural network as model and gradient descend as optimization algorithm called ListNet.</p> <h3>References</h3> <ul> <li><a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-2007-40.pdf" rel="external nofollow noopener" target="_blank">https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-2007-40.pdf</a></li> <li><a href="https://embracingtherandom.com/machine-learning/tensorflow/ranking/deep-learning/learning-to-rank-part-1/" rel="external nofollow noopener" target="_blank">https://embracingtherandom.com/machine-learning/tensorflow/ranking/deep-learning/learning-to-rank-part-1/</a></li> </ul> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=eaa57769a74a" width="1" height="1" alt=""></p> </body></html>